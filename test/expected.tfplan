------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

  # module.eks.data.template_file.kubeconfig will be read during apply
  # (config refers to values not yet known)
 <= data "template_file" "kubeconfig"  {
      + id       = (known after apply)
      + rendered = (known after apply)
      + template = <<~EOT
            apiVersion: v1
            preferences: {}
            kind: Config
            clusters:
            - cluster:
                server: ${endpoint}
                certificate-authority-data: ${cluster_auth_base64}
              name: ${kubeconfig_name}
            contexts:
            - context:
                cluster: ${kubeconfig_name}
                user: ${kubeconfig_name}
              name: ${kubeconfig_name}
            current-context: ${kubeconfig_name}
            users:
            - name: ${kubeconfig_name}
              user:
                exec:
                  apiVersion: client.authentication.k8s.io/v1alpha1
                  command: aws-iam-authenticator
                  args:
                    - "token"
                    - "-i"
                    - "${cluster_name}"
            ${aws_authenticator_env_variables}
        EOT
      + vars     = {
          + "aws_authenticator_env_variables" = ""
          + "cluster_auth_base64"             = (known after apply)
          + "cluster_name"                    = "development"
          + "endpoint"                        = (known after apply)
          + "kubeconfig_name"                 = "development"
        }
    }

  # module.eks.data.template_file.kubeconfig_json will be read during apply
  # (config refers to values not yet known)
 <= data "template_file" "kubeconfig_json"  {
      + id       = (known after apply)
      + rendered = (known after apply)
      + template = <<~EOT
            {
              "apiVersion": "v1",
              "clusters": [
                {
                  "cluster": {
                    "certificate-authority-data": "${cluster_auth_base64}",
                    "server": "${endpoint}"
                  },
                  "name": "${kubeconfig_name}"
                }
              ],
              "contexts": [
                {
                  "context": {
                    "cluster": "${kubeconfig_name}",
                    "user": "${kubeconfig_name}",
                  },
                  "name": "${kubeconfig_name}"
                }
              ],
              "current-context": "${kubeconfig_name}",
              "kind": "Config",
              "users": [
                {
                  "name": "${kubeconfig_name}",
                  "user": {
                    "exec": {
                      "apiVersion": "client.authentication.k8s.io/v1alpha1",
                      "command": "aws-iam-authenticator",
                      "args": [ "token", "-i", "${cluster_name}" ],
                      "env": [
            ${aws_authenticator_env_variables}
                      ]
                    }
                  }
                }
              ]
            }
        EOT
      + vars     = {
          + "aws_authenticator_env_variables" = ""
          + "cluster_auth_base64"             = (known after apply)
          + "cluster_name"                    = "development"
          + "endpoint"                        = (known after apply)
          + "kubeconfig_name"                 = "development"
        }
    }

  # module.eks.data.template_file.worker_aws_auth will be read during apply
  # (config refers to values not yet known)
 <= data "template_file" "worker_aws_auth"  {
      + id       = (known after apply)
      + rendered = (known after apply)
      + template = jsonencode(
            {
              + apiVersion = "v1"
              + data       = {
                  + mapRoles = "[ { \"rolearn\": \"${worker_role_arn}\", \"username\": \"system:node:{{EC2PrivateDNSName}}\", \"groups\": [ \"system:bootstrappers\", \"system:nodes\" ] }, ${map_roles} ]"
                }
              + kind       = "ConfigMap"
              + metadata   = {
                  + name      = "aws-auth"
                  + namespace = "kube-system"
                }
            }
        )
      + vars     = {
          + "map_roles"       = ""
          + "worker_role_arn" = (known after apply)
        }
    }

  # module.eks.aws_autoscaling_group.worker_per_az["0-us-west-2a"] will be created
  + resource "aws_autoscaling_group" "worker_per_az" {
      + arn                       = (known after apply)
      + availability_zones        = (known after apply)
      + default_cooldown          = (known after apply)
      + desired_capacity          = 1
      + force_delete              = false
      + force_delete_warm_pool    = false
      + health_check_grace_period = 300
      + health_check_type         = (known after apply)
      + id                        = (known after apply)
      + launch_configuration      = (known after apply)
      + max_size                  = 2
      + metrics_granularity       = "1Minute"
      + min_size                  = 0
      + name                      = (known after apply)
      + name_prefix               = "development-0-us-west-2a-"
      + protect_from_scale_in     = false
      + service_linked_role_arn   = (known after apply)
      + vpc_zone_identifier       = [
          + "subnet-77325d3e",
        ]
      + wait_for_capacity_timeout = "10m"

      + tag {
          + key                 = "Name"
          + propagate_at_launch = true
          + value               = "development-0"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/disabled"
          + propagate_at_launch = true
          + value               = "true"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/node-template/label/kiam/nodetype"
          + propagate_at_launch = true
          + value               = "server"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/node-template/label/node.kubernetes.io/role"
          + propagate_at_launch = true
          + value               = "kiam"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/node-template/taint/kiam/nodetype"
          + propagate_at_launch = true
          + value               = "server:NoSchedule"
        }
      + tag {
          + key                 = "kubernetes.io/cluster/development"
          + propagate_at_launch = true
          + value               = "owned"
        }
    }

  # module.eks.aws_autoscaling_group.worker_per_az["0-us-west-2b"] will be created
  + resource "aws_autoscaling_group" "worker_per_az" {
      + arn                       = (known after apply)
      + availability_zones        = (known after apply)
      + default_cooldown          = (known after apply)
      + desired_capacity          = 1
      + force_delete              = false
      + force_delete_warm_pool    = false
      + health_check_grace_period = 300
      + health_check_type         = (known after apply)
      + id                        = (known after apply)
      + launch_configuration      = (known after apply)
      + max_size                  = 1
      + metrics_granularity       = "1Minute"
      + min_size                  = 0
      + name                      = (known after apply)
      + name_prefix               = "development-0-us-west-2b-"
      + protect_from_scale_in     = false
      + service_linked_role_arn   = (known after apply)
      + vpc_zone_identifier       = [
          + "subnet-b1386cd6",
        ]
      + wait_for_capacity_timeout = "10m"

      + tag {
          + key                 = "Name"
          + propagate_at_launch = true
          + value               = "development-0"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/disabled"
          + propagate_at_launch = true
          + value               = "true"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/node-template/label/kiam/nodetype"
          + propagate_at_launch = true
          + value               = "server"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/node-template/label/node.kubernetes.io/role"
          + propagate_at_launch = true
          + value               = "kiam"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/node-template/taint/kiam/nodetype"
          + propagate_at_launch = true
          + value               = "server:NoSchedule"
        }
      + tag {
          + key                 = "kubernetes.io/cluster/development"
          + propagate_at_launch = true
          + value               = "owned"
        }
    }

  # module.eks.aws_autoscaling_group.worker_per_az["1-us-west-2a"] will be created
  + resource "aws_autoscaling_group" "worker_per_az" {
      + arn                       = (known after apply)
      + availability_zones        = (known after apply)
      + default_cooldown          = (known after apply)
      + desired_capacity          = 1
      + force_delete              = false
      + force_delete_warm_pool    = false
      + health_check_grace_period = 300
      + health_check_type         = (known after apply)
      + id                        = (known after apply)
      + launch_configuration      = (known after apply)
      + max_size                  = 2
      + metrics_granularity       = "1Minute"
      + min_size                  = 0
      + name                      = (known after apply)
      + name_prefix               = "development-1-us-west-2a-"
      + protect_from_scale_in     = false
      + service_linked_role_arn   = (known after apply)
      + vpc_zone_identifier       = [
          + "subnet-77325d3e",
        ]
      + wait_for_capacity_timeout = "10m"

      + tag {
          + key                 = "Name"
          + propagate_at_launch = true
          + value               = "development-1"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/disabled"
          + propagate_at_launch = true
          + value               = "true"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/node-template/label/node.kubernetes.io/role"
          + propagate_at_launch = true
          + value               = "infrastructure"
        }
      + tag {
          + key                 = "kubernetes.io/cluster/development"
          + propagate_at_launch = true
          + value               = "owned"
        }
    }

  # module.eks.aws_autoscaling_group.worker_per_az["1-us-west-2b"] will be created
  + resource "aws_autoscaling_group" "worker_per_az" {
      + arn                       = (known after apply)
      + availability_zones        = (known after apply)
      + default_cooldown          = (known after apply)
      + desired_capacity          = 1
      + force_delete              = false
      + force_delete_warm_pool    = false
      + health_check_grace_period = 300
      + health_check_type         = (known after apply)
      + id                        = (known after apply)
      + launch_configuration      = (known after apply)
      + max_size                  = 1
      + metrics_granularity       = "1Minute"
      + min_size                  = 0
      + name                      = (known after apply)
      + name_prefix               = "development-1-us-west-2b-"
      + protect_from_scale_in     = false
      + service_linked_role_arn   = (known after apply)
      + vpc_zone_identifier       = [
          + "subnet-b1386cd6",
        ]
      + wait_for_capacity_timeout = "10m"

      + tag {
          + key                 = "Name"
          + propagate_at_launch = true
          + value               = "development-1"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/disabled"
          + propagate_at_launch = true
          + value               = "true"
        }
      + tag {
          + key                 = "k8s.io/cluster-autoscaler/node-template/label/node.kubernetes.io/role"
          + propagate_at_launch = true
          + value               = "infrastructure"
        }
      + tag {
          + key                 = "kubernetes.io/cluster/development"
          + propagate_at_launch = true
          + value               = "owned"
        }
    }

  # module.eks.aws_ec2_tag.private["subnet-77325d3e"] will be created
  + resource "aws_ec2_tag" "private" {
      + id          = (known after apply)
      + key         = "kubernetes.io/role/internal-elb"
      + resource_id = "subnet-77325d3e"
      + value       = "true"
    }

  # module.eks.aws_ec2_tag.private["subnet-b1386cd6"] will be created
  + resource "aws_ec2_tag" "private" {
      + id          = (known after apply)
      + key         = "kubernetes.io/role/internal-elb"
      + resource_id = "subnet-b1386cd6"
      + value       = "true"
    }

  # module.eks.aws_eks_cluster.this will be created
  + resource "aws_eks_cluster" "this" {
      + arn                   = (known after apply)
      + certificate_authority = (known after apply)
      + created_at            = (known after apply)
      + endpoint              = (known after apply)
      + id                    = (known after apply)
      + identity              = (known after apply)
      + name                  = "development"
      + platform_version      = (known after apply)
      + role_arn              = (known after apply)
      + status                = (known after apply)
      + tags                  = {
          + "builtWith" = "terraform"
        }
      + tags_all              = {
          + "builtWith" = "terraform"
        }
      + version               = "1.11"

      + kubernetes_network_config {
          + service_ipv4_cidr = (known after apply)
        }

      + timeouts {
          + create = "30m"
          + delete = "15m"
          + update = "60m"
        }

      + vpc_config {
          + cluster_security_group_id = (known after apply)
          + endpoint_private_access   = false
          + endpoint_public_access    = true
          + public_access_cidrs       = (known after apply)
          + security_group_ids        = (known after apply)
          + subnet_ids                = [
              + "subnet-063f6b61",
              + "subnet-5a305f13",
              + "subnet-77325d3e",
              + "subnet-b1386cd6",
            ]
          + vpc_id                    = (known after apply)
        }
    }

  # module.eks.aws_iam_instance_profile.worker will be created
  + resource "aws_iam_instance_profile" "worker" {
      + arn         = (known after apply)
      + create_date = (known after apply)
      + id          = (known after apply)
      + name        = "EKS_worker.development"
      + path        = "/"
      + role        = "EKS_worker.development"
      + tags        = {
          + "builtWith" = "terraform"
        }
      + tags_all    = {
          + "builtWith" = "terraform"
        }
      + unique_id   = (known after apply)
    }

  # module.eks.aws_iam_role.cluster will be created
  + resource "aws_iam_role" "cluster" {
      + arn                   = (known after apply)
      + assume_role_policy    = jsonencode(
            {
              + Statement = [
                  + {
                      + Action    = "sts:AssumeRole"
                      + Effect    = "Allow"
                      + Principal = {
                          + Service = "eks.amazonaws.com"
                        }
                      + Sid       = "EKSClusterAssumeRole"
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + create_date           = (known after apply)
      + force_detach_policies = true
      + id                    = (known after apply)
      + managed_policy_arns   = (known after apply)
      + max_session_duration  = 3600
      + name                  = "EKS_control.development"
      + path                  = "/"
      + tags                  = {
          + "builtWith" = "terraform"
        }
      + tags_all              = {
          + "builtWith" = "terraform"
        }
      + unique_id             = (known after apply)

      + inline_policy {
          + name   = (known after apply)
          + policy = (known after apply)
        }
    }

  # module.eks.aws_iam_role.worker will be created
  + resource "aws_iam_role" "worker" {
      + arn                   = (known after apply)
      + assume_role_policy    = jsonencode(
            {
              + Statement = [
                  + {
                      + Action    = "sts:AssumeRole"
                      + Effect    = "Allow"
                      + Principal = {
                          + Service = "ec2.amazonaws.com"
                        }
                      + Sid       = "EKSWorkerAssumeRole"
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + create_date           = (known after apply)
      + force_detach_policies = true
      + id                    = (known after apply)
      + managed_policy_arns   = (known after apply)
      + max_session_duration  = 3600
      + name                  = "EKS_worker.development"
      + path                  = "/"
      + tags                  = {
          + "builtWith" = "terraform"
        }
      + tags_all              = {
          + "builtWith" = "terraform"
        }
      + unique_id             = (known after apply)

      + inline_policy {
          + name   = (known after apply)
          + policy = (known after apply)
        }
    }

  # module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy will be created
  + resource "aws_iam_role_policy_attachment" "cluster_AmazonEKSClusterPolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
      + role       = "EKS_control.development"
    }

  # module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy will be created
  + resource "aws_iam_role_policy_attachment" "cluster_AmazonEKSServicePolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
      + role       = "EKS_control.development"
    }

  # module.eks.aws_iam_role_policy_attachment.worker_AmazonEC2ContainerRegistryReadOnly will be created
  + resource "aws_iam_role_policy_attachment" "worker_AmazonEC2ContainerRegistryReadOnly" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
      + role       = "EKS_worker.development"
    }

  # module.eks.aws_iam_role_policy_attachment.worker_AmazonEKSWorkerNodePolicy will be created
  + resource "aws_iam_role_policy_attachment" "worker_AmazonEKSWorkerNodePolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
      + role       = "EKS_worker.development"
    }

  # module.eks.aws_iam_role_policy_attachment.worker_AmazonEKS_CNI_Policy will be created
  + resource "aws_iam_role_policy_attachment" "worker_AmazonEKS_CNI_Policy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
      + role       = "EKS_worker.development"
    }

  # module.eks.aws_launch_configuration.worker[0] will be created
  + resource "aws_launch_configuration" "worker" {
      + arn                         = (known after apply)
      + associate_public_ip_address = false
      + ebs_optimized               = true
      + enable_monitoring           = true
      + iam_instance_profile        = (known after apply)
      + id                          = (known after apply)
      + image_id                    = "ami-0dcb143eaaa2351b7"
      + instance_type               = "t3.small"
      + key_name                    = "development_operations"
      + name                        = (known after apply)
      + name_prefix                 = "EKS_development-0-"
      + security_groups             = (known after apply)
      + user_data                   = (known after apply)

      + ebs_block_device {
          + delete_on_termination = (known after apply)
          + device_name           = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + no_device             = (known after apply)
          + snapshot_id           = (known after apply)
          + throughput            = (known after apply)
          + volume_size           = (known after apply)
          + volume_type           = (known after apply)
        }

      + metadata_options {
          + http_endpoint               = (known after apply)
          + http_put_response_hop_limit = (known after apply)
          + http_tokens                 = (known after apply)
        }

      + root_block_device {
          + delete_on_termination = true
          + encrypted             = (known after apply)
          + iops                  = 0
          + throughput            = (known after apply)
          + volume_size           = 100
          + volume_type           = "gp2"
        }
    }

  # module.eks.aws_launch_configuration.worker[1] will be created
  + resource "aws_launch_configuration" "worker" {
      + arn                         = (known after apply)
      + associate_public_ip_address = false
      + ebs_optimized               = true
      + enable_monitoring           = true
      + iam_instance_profile        = (known after apply)
      + id                          = (known after apply)
      + image_id                    = "ami-0dcb143eaaa2351b7"
      + instance_type               = "t3.xlarge"
      + key_name                    = "development_operations"
      + name                        = (known after apply)
      + name_prefix                 = "EKS_development-1-"
      + security_groups             = (known after apply)
      + user_data                   = (known after apply)

      + ebs_block_device {
          + delete_on_termination = (known after apply)
          + device_name           = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + no_device             = (known after apply)
          + snapshot_id           = (known after apply)
          + throughput            = (known after apply)
          + volume_size           = (known after apply)
          + volume_type           = (known after apply)
        }

      + metadata_options {
          + http_endpoint               = (known after apply)
          + http_put_response_hop_limit = (known after apply)
          + http_tokens                 = (known after apply)
        }

      + root_block_device {
          + delete_on_termination = true
          + encrypted             = (known after apply)
          + iops                  = 0
          + throughput            = (known after apply)
          + volume_size           = 100
          + volume_type           = "gp2"
        }
    }

  # module.eks.aws_security_group.cluster will be created
  + resource "aws_security_group" "cluster" {
      + arn                    = (known after apply)
      + description            = "Managed by Terraform"
      + egress                 = (known after apply)
      + id                     = (known after apply)
      + ingress                = (known after apply)
      + name                   = (known after apply)
      + name_prefix            = "EKS_control.development-"
      + owner_id               = (known after apply)
      + revoke_rules_on_delete = false
      + tags                   = {
          + "Name" = "eks-additional-sg-development.us-west-2"
        }
      + tags_all               = {
          + "Name" = "eks-additional-sg-development.us-west-2"
        }
      + vpc_id                 = "vpc-643a0203"
    }

  # module.eks.aws_security_group_rule.cluster-egress["all"] will be created
  + resource "aws_security_group_rule" "cluster-egress" {
      + cidr_blocks              = [
          + "0.0.0.0/0",
        ]
      + from_port                = 0
      + id                       = (known after apply)
      + protocol                 = "-1"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 0
      + type                     = "egress"
    }

  # module.eks.aws_security_group_rule.cluster-ingress["all"] will be created
  + resource "aws_security_group_rule" "cluster-ingress" {
      + from_port                = 0
      + id                       = (known after apply)
      + protocol                 = "-1"
      + security_group_id        = (known after apply)
      + self                     = true
      + source_security_group_id = (known after apply)
      + to_port                  = 0
      + type                     = "ingress"
    }

  # module.eks.aws_security_group_rule.cluster-ingress["https"] will be created
  + resource "aws_security_group_rule" "cluster-ingress" {
      + cidr_blocks              = (known after apply)
      + from_port                = 443
      + id                       = (known after apply)
      + protocol                 = (known after apply)
      + security_group_id        = (known after apply)
      + self                     = (known after apply)
      + source_security_group_id = (known after apply)
      + to_port                  = (known after apply)
      + type                     = "ingress"
    }

  # module.eks.aws_security_group_rule.cluster-ingress["kubelet"] will be created
  + resource "aws_security_group_rule" "cluster-ingress" {
      + cidr_blocks              = (known after apply)
      + from_port                = 10250
      + id                       = (known after apply)
      + protocol                 = (known after apply)
      + security_group_id        = (known after apply)
      + self                     = (known after apply)
      + source_security_group_id = (known after apply)
      + to_port                  = (known after apply)
      + type                     = "ingress"
    }

  # module.eks.null_resource.apply_flux_deployment[0] will be created
  + resource "null_resource" "apply_flux_deployment" {
      + id       = (known after apply)
      + triggers = (known after apply)
    }

  # module.eks.null_resource.update_worker_aws_auth will be created
  + resource "null_resource" "update_worker_aws_auth" {
      + id       = (known after apply)
      + triggers = (known after apply)
    }

Plan: 24 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.

